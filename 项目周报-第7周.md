# 项目周报

日期：2025-05-17

项目实践题目：文本的匹配与推荐

## 实践内容
完成“支线任务11”
阅读完Gao 2023
### 感受
根据文章（Gao 2023）查询了一篇23年的（ PROMPTAGATOR : FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES）和 几篇22年的相关文章（Task-aware Retrieval with Instructions、Autoregressive Search Engines:Generating Substrings as Document Identifiers、Unsupervised Corpus Aware Language Model Pre-training
 for Dense Passage Retrieval、Training compute-optimal large language models）并粗略地阅读了一遍。  
阅读这几篇文章，发现作者基本上都是对一个或多个模型进行微调或者结合、或者寻找特殊架构或者引入函数变量等方法，对模型进行一定的优化，结合大语言模型然后经过常见的几个数据集对其进行训练最后得到性能对比其他模型有着较好提升的模型。  
#### 阅读收获  
HyDE方法：  
首先用图画展示了HyDE在instructGPT上运行的示意图，显示了 TREC DL、TREC-COVID 和 Mr.TyDi的三个查询，并且能够看到三个查询的问题都得到了回答。  
开始介绍了密集检索模型捕捉查询和文档之间相似性的方法,然后简述了无监督学习能够以HyDE方法规避没有相关性判断和/或分数作为训练数据的学习难点。同时还考虑了指令跟踪LM。然后将查询映射到“假设“文档（从g中取样，将INST设置为：写一段话回答问题”。但同时强调生成的文件并不真实，需要通过“假”文档实现捕捉相关模式，并且通过NLG模型取代了显式建模。最后通过文档编码器的编码函数输出回答）。  
HyDE的实现：  
1、实验设置：采用了广泛采用的模型，InstructGPT和Contriever模型变体，使用了网络测试集以及来自BEIR的七个数据集并且使用 Pyserini 工具包（Lin 等人，2021a）进行了检索实验。在实验中也使用了多种模型（DPR和ANCE模型、Contriever和mContriever的微调模型）、由于没有考虑到其它系统与他们的设置不同，他们的HyDE方法虽然提高了性能但是也牺牲了系统的灵活性和通用性。  
2、网络搜索、低资源检索和多语言检索：在TREC DL19 和TREC DL20的检索表中，HyDE在精确度和召回率的两个指标较Contriever有所提高，并且HyDE性能远超于BM25。（网络搜索后面一串的比较没看明白），从表2各项数据对比能看出在低资源检索中，HyDE一样较其他两种方法有着一定程度的性能提升,但同时，对于一些资源不如英语或者法语丰富的语言，LLMs的参数化程度过高导致训练不足。（感觉像是共性：语言资源不够丰富的语言可能都会导致模型训练不足）。   
HyDE的局限性：  
依赖于 LLM 的实时生成，因此可能不适合要求高吞吐量或低延迟的任务。且与大多数当代 LLM 一样，HyDE 在生成时可能会偏好某些内容，从而使最终搜索结果出现偏差。 
下一周：继续阅读Gao 2023相关的文章或看作者主页中的论文，查找运用与Gao 2023相同或类似方法对模型或方法进行优化的文章找寻这种方法的共通点，同时了解密集检索相关内容。  