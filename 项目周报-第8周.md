# 项目周报

日期：2025-05-24

项目实践题目：文本的匹配与推荐  

## 实践内容  
翻看作者Luyu Gao的主页相关论文  
### 阅读收获  
在作者Luyu Gao的主页找到了四篇2023年前后的相关文章（Active retrieval augmented generation、Unsupervised corpus aware language model pre-training for dense passage retrieval、Condenser: a Pre-training Architecture for Dense Retrieval、COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List），这四篇的引用率都很高，达到了几百次。    
同时，这四篇文章的同一个目标都是优化密集检索以及文本匹配的性能。并且，这四篇文章中的两篇都提到了同一个架构，即Condenser架构，这种架构基于 Transformer 编码器，通过在预训练阶段引入一个特殊的“Condenser Head”来优化模型结构，使其更适合于密集编码器的任务，它通过在早期和晚期编码器层之间建立一个短路连接，使得Condenser 强制模型在预训练阶段就关注于全局信息的聚合，而不是仅仅依赖于局部信息。并且在晚一点的第二篇文章更是提出了coCondenser（基于 Condenser 架构，通过无监督的语料级对比损失来预训练密集检索模型），它相比Condenser多加了一个对比损失函数，使得来自同一文档的片段的 CLS 嵌入接近，而来自不同文档的片段的 CLS 嵌入远离。并且还采用了梯度缓存技术，将表示梯度和编码器梯度计算解耦，从而避免了大批次数据同时占用 GPU 内存，使得密集检索的性能得到了进一步的提升。  
而其他两篇则是用通用的主动检索增强生成框架、FLARE方法和COIL信息检索架构。这方法是与前面提及的两篇文章中的大方向相同，都是运用一种架构模型，通过文本或文字向量的相似度、编码器聚合的信息结合使得密集检索的性能提升完成对上下文的匹配。  
综合作者GaoLuyu的这几篇论文来看，想要优化密集检索模型完成文本匹配，可以对一个架构进行微调，引入关键函数，使其在原有架构的基础上得到性能的进一步提升，又或者是提出一种新型适配架构能够更好地完成零点密集检索与文本文字向量匹配任务。  
关于密集检索：  
密集检索是一种通过将文档和查询转换为高维向量表示，从而在向量空间中进行匹配的检索技术，它能够用于多种模型（如BERT等），能够捕捉查询和文档之间的语义相关性，即使没有直接的词汇重叠，但是需要更多的计算资源来训练和运行深度学习模型（但上文有提到能够利用梯度缓存技术，避免大批次数据同时占用 GPU 内存从而避免使用太多计算资源），但它因为向量空间的维度不直观所以通常不容易对密集检索得到的结果进行直接解释。  
下周：以密集检索为基础，搜索关于文本匹配的近年的相关论文。